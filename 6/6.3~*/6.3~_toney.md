# 마스의 주요 처리 방식

본격적으로 성능에 크게 영향을 미치는 실행 계획과 연관이 있는 단위 작업에 대해 알아보자. 본 내용 중, 풀 테이블 스캔을 제외한 나머지는 모두 스토리지 엔진이 아니라 마스 엔진에서 처리되는 내용이다. 이런 작업은 성능에 미치는 영향력이 큰데, 모두 쿼리의 성능을 저하시키는 데 한몫하는 작업이다. 스토리지 엔진에서 읽은 레코드를 마스 엔진이 아무런 가공 작업도 하지 않고 사용자에게 반환한다면 최상의 성능을 보장하는 쿼리겠지만 대부분의 쿼리는 그렇지 않다. 그렇기에 마스 엔진에서 처리하는 데 시간이 오래 걸리는 작업의 원리를 알아두자.

## 풀 테이블 스캔

인덱스를 사용하지 않고 테이블의 데이터를 처음부터 끝까지 읽어서 요청된 작업을 처리하는 작업을 의미한다. 

![image](https://user-images.githubusercontent.com/37579660/101336669-15771700-38be-11eb-82f1-599fd1f9cba4.png)
위와 같은 조건에서 풀 테이블 스캔을 선택한다.

일반적으로 테이블의 전체 크기는 인덱스보다 훨씬 크다. 그렇기에 이 작업은 상당히 많은 디스크 읽기가 필요하다. 그래서 대부분의 DBMS는 풀 테이블 스캔을 실행할 때 한꺼번에 여러 개의 블록이나 페이지를 읽어오는 기능이 있으며, 그 수를 조절할 수 있다. 하지만 MySQL에는 풀 테이블 스캔을 실행할 때 한꺼번에 몇 개씩 페이지를 읽어올지 설정하는 변수는 없다. 그래서 MySQL이 풀 테이블 스캔을 실행할 때 디스크로부터 페이지를 하나씩 읽어오는 것으로 생각할 때가 많다. 

이것은 MyISAM에서는 맞지만 InnoDB에서는 틀린 말이다. InnoDB 스토리지 엔진은 특정 테이블의 연속된 데이터 페이지가 읽히면 백그라운드 스레드에 의해 리드 어헤드 작업이 자동으로 시작된다. 리드 어헤드란 어떤 영역의 데이터가 앞으로 필요해지리라는 것을 예측해서 요청이 오기 전에 미리 디스크에서 읽어 InnoDB의 버퍼 풀에 가져다 두는 것을 의미한다. 즉, 풀 테이블 스캔이 실행되면 처음 몇 개의 데이터 페이지는 포그라운드 스레드가 페이지 읽기를 실행하지만 특정 시점부터는 읽기 작업을 백그라운드 스레드로 넘긴다. 백그라운드 스레드가 읽기를 넘겨받는 시점부터는 한번에 4개 또는 8개씩의 페이지를 읽으면서 계속 그 수를 증가시킨다. 이때 한 번에 최대 64개의 데이터 페이지까지 읽어서 버퍼 풀에 저장해 둔다. 포그라운드 스레드는 미리 버퍼 풀에 준비된 데이터를 가져다 사용하기만 하면 되므로 쿼리가 상당히 빨리 처리되는 것이다.

MySQL 5.1의 InnoDB 플러그인 버전부터는 언제 리드 어헤드를 시작할지 시스템 변수를 통해 변경할 수 있다. 그 시스템 변수 이름이 innodb_read_ahead_threshold인데 일반적으로 디폴트 설정으로도 충분하지만 데이터 웨어하우스용으로 MySQL을 사용한다면 이 옵션을 더 낮은 값으로 설정해서 더 자주 리드 어헤드가 시작되도록 유도하는 것도 좋은 방법이다.

- 질문 : 데이터웨어하우스

    > 데이터웨어하우스란 : 정보에 입각한 의사 결정을 내릴 수 있도록 분석 가능한 정보의 중앙 저장소. DW라고 불린다. 데이터는 트랜잭션 시스템, RDMS 및 기타 소스로부터 보통은 정기적으로 데이터 웨어하우스로 들어간다. 그리고 DBA, Data Scientist들은 비즈니스 인텔리전스 도구, SQL 클라이언트 및 기타 응용 분석 프로그램을 통해 데이터에 액세스하게 된다. 
    정리하자면 DW는 기존 정보를 활용해 더 나은 정보를 제공하고, 데이터의 품질을 향상시키며, 조직의 변화를 지원하고 비용과 자원관리의 효율성을 향상시키는 것이 목적이다.

    [https://kr.analysisman.com/2020/08/cloud-dw-cdp.html](https://kr.analysisman.com/2020/08/cloud-dw-cdp.html)

    ![image](https://user-images.githubusercontent.com/37579660/101336701-1d36bb80-38be-11eb-8b43-1c78a50e0e72.png)
    [https://sites.google.com/site/sunnydba234234/mysql/mysqlseoljeong/server_variables/innodb_random_read_ahead](https://sites.google.com/site/sunnydba234234/mysql/mysqlseoljeong/server_variables/innodb_random_read_ahead)

    즉 순차적으로 읽어지는 page의 개수가 설정값과 같거나 크면 비동기적으로 리드 어헤드를 시작하여 백그라운드 스레드에 그 페이지 수만큼의 페이지를 로딩한다. 즉 대량의 데이터 조회가 빈번할 DW 같은 곳에는 미리 디폴트 값을 낮춰놔서 비동기적으로 리드 어헤드를 많이 활용할 수 있도록 처리한다는 의미이다. 

## ORDER BY 처리 (Using filesort)

레코드 1~2건을 가져오는 쿼리를 제외하면 대부분의 SELECT 쿼리에서 정렬은 필수적으로 사용된다. 데이터웨어하우스처럼 대량의 데이터를 조회해서 일괄 처리하는 기능이 아니라면 아마도 레코드 정렬 요건은 대부분의 조회 쿼리에 포함돼 있을 것이다. 정렬을 처리하기 위해서는 인덱스를 이용하는 방법과 쿼리가 실행될 때 Filesort라는 별도의 처리를 이용하는 방법으로 나눌 수 있다.

![image](https://user-images.githubusercontent.com/37579660/101336836-46efe280-38be-11eb-8809-8527fba3697a.png)
- 질문 : InnoDB 버퍼 풀, MyISAM의 키 캐시용 메모리

아래와 같은 이유로 모든 정렬을 인덱스를 이용하도록 튜닝하기란 거의 불가능하다.

![image](https://user-images.githubusercontent.com/37579660/101336845-4a836980-38be-11eb-8903-c2ebac0cdb5b.png)
MySQL이 인덱스를 이용하지 않고 별도의 정렬 처리를 수행했는지를 실행 계획의 Extra 칼럼에 Using filesort라는 코멘트가 표시되는지로 판단할 수 있다. 여기서는 MySQL의 정렬이 어떻게 처리되는지 살펴보고자 한다. MySQL의 정렬 특성을 이해하면 쿼리를 튜닝할 때 어떻게 하면 조금이라도 더 빠른 쿼리가 될지 쉽게 판단할 수 있을 것이다.

### 소트 버퍼

- MySQL은 정렬을 수행하기 위해 별도의 메모리 공간을 할당받아서 사용하는데, 이 메모리 공간을 소트 버퍼라고 한다. 소트 버퍼는 정렬이 필요한 경우에만 할당되며, 버퍼의 크기는 정렬해야 할 레코드의 크기에 따라 가변적으로 증가하지만 최대 사용 가능한 소트 버퍼의 공간은 sort_buffer_size라는 시스템 변수로 설정할 수 있다. 소트 버퍼를 위한 메모리 공간은 쿼리의 실행이 완료되면 즉시 시스템으로 반납된다.
- 이렇게 보면 이상적이지만 지금부터 정렬이 왜 문제가 되는지를 살펴보자. 정렬해야 할 레코드가 아주 소량이어서 메모리에 할당된 소트 버퍼만으로 정렬할 수 있다면 아주 빠르게 정렬이 처리될 것이다. 하지만 정렬해야 할 레코드의 건수가 소트 버퍼로 할당된 공간보다 크다면 어떻게 될까? 이때 MySQL은 정렬해야 할 레코드를 여러 조각으로 나눠서 처리하는데, 이 과정에서 임시 저장을 위해 디스크를 사용한다.

![image](https://user-images.githubusercontent.com/37579660/101336896-5a9b4900-38be-11eb-965c-07cf00fadf4f.png)
- 이처럼 메모리의 소트 버퍼에서 정렬을 수행하고, 그 결과를 임시로 디스크에 기록해 둔다. 그리고 그다음 레코드를 가져와서 다시 정렬해서 반복적으로 디스크에 임시 저장한다. 이처럼 각 버퍼 크기 만큼씩 정렬된 레코드를 다시 병합하면서 정렬을 수행해야 한다. 이 병합 작업을 멀티 머지라고 표현하며, 수행된 멀티 머지 횟수는 Sort_merge_passes라는 상태 변수에 누적된다.
- 질문 : 이걸 확인해보고 싶어요~
- 이 작업들은 모두 디스크의 쓰기와 읽기를 유발하며, 레코드 건수가 많을수록 이 반복 작업의 횟수가 많아진다. 소트 버퍼를 크게 설정하면 디스크를 사용하지 않아서 더 빨라질 것으로 생각할 수 있지만 실제 벤치마크 결과로는 거의 차이가 없었다. 소트버퍼는 256KB~512KB 사이에서 최적의 성능을 보였다. 다만 8MB 이상에서 더 향상되었다는 자료도 있는데, 이는 웹과 같은 OLTP 성격의 쿼리가 아니라 대용량의 정렬 작업에 해당되는 내용일 것으로 보인다.

![image](https://user-images.githubusercontent.com/37579660/101336905-5d963980-38be-11eb-8615-ad7ea57b9be1.png)
- 질문 : OLTP 성격의 쿼리는 무엇인가요?
[https://too612.tistory.com/511](https://too612.tistory.com/511)

    Online Transaction Processing : 데이터 자체의 처리에 중점을 두는 관점. 복수의 사용자 PC에서 발생되는 트랜잭션을 DB서버가 처리하고, 그 결과를 요청한 사용자 PC에 되돌려주는 과정을 뜻한다. 즉 한개의 요청 작업을 처리하는 과정으로 생각하면 편하다.  조금 더 복잡하게 말하자면 1개의 트랜잭션에서 발생되는 INSERT, UPDATE, DELETE의 과정의 무결성을 보장하여 처리하고 그 결과를 SELECT하는 과정이다. 
    Online Analytical Processing : 이미 저장된 데이터를 기반으로 분석하는데 중점을 둔 관점. DW에 저장된 데이터를 분석하고, 데이터 분석을 통해 사용자에게 유의미한 정보를 제공해주는 처리 방법을 의미한다. 즉 기존에 저장되어 있는 데이터를 사용자의 요구와 목적에 맞게 분석하여 정보를 제공하는 개념을 의미한다. 
    둘의 차이점 : 전자는 현재의 데이터가 얼마나 정확하고 무결한지가 중요하다. 그러기에 데이터의 저장, 삭제, 수정 등 실질적인 데이터를 수정하는 작업을 의미한다. 후자는 저장된 데이터를 바탕으로 어떤 정보를 제공하는지가 중요하다. 그러기에 데이터가 무결하고 정확하다는 전제하에 사용자가 원하는 정보를 어떻게 표현하고 제공하는지가 중요하다. 

    ![image](https://user-images.githubusercontent.com/37579660/101336917-5ff89380-38be-11eb-94ab-ca7a956825e4.png)
- 경험상으로 소트버퍼는 56KB~1MB이 적절하다. 정렬을 위해 할당받는 소트 버퍼는 세션 메모리 영역에 해당된다. 즉 소트 버퍼는 여러 클라이언트가 공유해서 사용할 수 있는 영역이 아니다. 커넥션이 많으면 많을수록, 정렬 작업이 많으면 많을수록 소트 버퍼로 소비되는 메모리 공간이 커짐을 의미한다. 소트 버퍼의 크기를 10~20MB와 같이 터무니 없이 많이 설정할 수 있다. 이럴 때 대량의 레코드를 정렬하는 쿼리가 여러 커넥션에서 동시에 실행되면 운영체제는 메모리 부족 현상을 겪는다. 메모리가 없는 경우에는 OS의 OOK-Killer가 여유 메모리를 확보하기 위해 프로세스를 강제 종료시킬 것이다. 그런데 OOK-Killer는 메모리를 가장 많이 사용하고 있는 프로세스를 강제 종료한다. 일반적으로 마스 서버가 가장 많은 메모리를 사용하기 때문에 강제 종료 1순위가 된다.

- 소트 버퍼가 크면 > 디스크 R/W 사용량을 줄일 수 있다. 하지만 너무 크면 서버의 메모리가 부족해진다. 적절한 크기가 중요하다.

### 정렬 알고리즘

- 레코드 정렬 시, 레코드 전체를 소트 버퍼에 담을지, 정렬 기준 칼럼만 소트 버퍼에 담을지에 따라 두가지 정렬 알고리즘으로 나눌 수 있다.
- 싱글 패스 알고리즘 : 소트 버퍼에 정렬 기준 칼럼을 포함해 SELECT되는 칼럼 전부를 담아서 정렬을 수행하는 방법이며 마스 5.0 이후 최근 버전에서 도입된 정렬 방법이다.

![image](https://user-images.githubusercontent.com/37579660/101337022-85859d00-38be-11eb-9019-b694ee81deac.png)

![image](https://user-images.githubusercontent.com/37579660/101337029-874f6080-38be-11eb-8240-416ce74ad92d.png)

- 투 패스 알고리즘 : 정렬 대상 칼럼과 프라이머리 키값만을 소트 버퍼에 담아서 정렬을 수행하고, 정렬된 순서대로 다시 프라이머리 키로 테이블을 읽어서 SELECT할 칼럼을 가져오는 알고리즘. 예전 마스에서 사용하던 방법. 하지만 5.0, 5.1, 5.5에도 특정 조건이 되면 이 방법을 사용한다.

![image](https://user-images.githubusercontent.com/37579660/101337035-89b1ba80-38be-11eb-8801-602148e9a317.png)

![image](https://user-images.githubusercontent.com/37579660/101337040-8ae2e780-38be-11eb-992c-fbe593d9a04d.png)
- 투 패스 알고리즘은 테이블을 두 번 읽어야 하지만 싱글 패스 알고리즘은 그런 불합리가 없다. 그렇지만 싱글 패스 알고리즘은 더 많은 소트 버퍼 공간이 필요하다. 128KB로 계산했을 때에 투 패스 알고리즘은 7천건의 레코드를 정렬할 수 있지만 싱글 패스 알고리즘은 그것의 반 정도 밖에 정렬할 수 없다. 그리고 이것은 소트 버퍼 공간의 크기와 레코드의 크기에 의존적이다.
- 마스 5점대 버전에서 투 패스 정렬 알고리즘을 사용하는 경우
    - 레코드의 크기가 max_length_for_sort_data 파라미터로 설정된 값보다 클 때
    - BLOB나 TEXT 타입의 칼럼이 SELECT 대상에 포함ㄷ할 때.
- 싱글 패스 알고리즘은 정렬 대상 레코드의 크기나 건수가 작은 경우 빠른 성능을 보이며, 투 패스 알고리즘은 정렬 대상 레코드의 크기나 건수가 상당히 많은 경우 효율적이라고 볼 수 있다.

![image](https://user-images.githubusercontent.com/37579660/101337043-8c141480-38be-11eb-967e-48749a335a72.png)

## 정렬의 처리 방식

- 쿼리에 ORDER BY가 사용되면 반드시 다음 3가지 처리 방식 중 하나로 정렬이 처리된다. 일반적으로 아래로 갈수록 처리가 느려진다.

![image](https://user-images.githubusercontent.com/37579660/101337231-c1b8fd80-38be-11eb-913f-27b0aa247da0.png)

- 옵티마이저는 정렬 처리를 위해 인덱스를 이용할 수 있을지를 검토할 것이다. 만약 인덱스를 이용할 수 있다면 별도의 Filesort 과정 없이 인덱스를 순서대로 읽어서 결과를 반환한다. 하지만 인덱스를 사용할 수 없다면 WHERE 조건에 일치하는 레코드를 검색해 정렬 버퍼에 저장하면서 정렬을 처리할것이다. 이때 마스 옵티마이저는 정렬 대상 레코드를 최소화하기 위해 다음 두 가지 방법중 하나를 선택한다.
    1. 드라이빙 테이블만 정렬한 다음 조인을 수행
    2. 조인이 끝나고 일치하는 레코드를 모두 가져온 후 정렬을 수행
- 일반적으로 조인이 수행되면서 레코드 건수는 거의 배수로 불어나기 때문에 가능하다면 드라이빙 테이블만 정렬한 다음 조인을 수행하는 방법이 효율적이다. 그래서 두 번째 방법보다는 첫 번째 방법이 더 효율적으로 처리된다. 이제 다시 표의 세가지 정렬 처리 방법을 자세하게 알아보자.

- 인덱스를 이용한 정렬
    - 반드시 ORDER BY에 명시된 칼러이 제일 먼저 읽는 테이블(조인이 사용된 경우 드라이빙 테이블)에 속하고, ORDER BY의 순서대로 생성된 인덱스가 있어야 한다. 또한 WHERE 절에 첫 번째 읽는 테이블의 칼럼에 대한 조건이 있다면 그 조건과 ORDER BY는 값은 인덱스를 사용할 수 있어야 한다. 그리고 B-Tree 계열의 인덱스가 아닌 해시 인덱스나 전문 검색 인덱스 등에서는 인덱스를 이용한 정렬을 사용할 수 없다. 예외적으로 R-Tree도 B-Tree 계열이지만 특성상 이 방식을 사용할 수 없다. 여러 테이블이 조인되는 경우에는 네스티드루프 방식의 조인에서만 이 방식을 사용할 수 있다.
    - 인덱스를 이용해 정렬이 처리되는 경우에는 실제 인덱스의 값이 정렬돼 있기 때문에 인덱스의 순서대로 읽기만 하면된다. 실제로 마스 엔진에서 정렬을 위한 추가 작업을 수행하지는 않는다. 다음 예제처럼 ORDER BY가 있건 없건 같은 인덱스를 레인지 스캔해서 나온 결과는 같은 순서로 출력되는 것을 확인할 수 있다. 없어도 정렬이 되는 이유는 employees 테이블의 PK를 읽고 그 다음으로 salaries 테이블을 조인했기 때문이다.

    ![image](https://user-images.githubusercontent.com/37579660/101337239-c54c8480-38be-11eb-810a-b66adc5a6ad7.png)
    
    - ORDER BY를 생략 가능하다고 생략하면 예외가 발생하거나 스키마가 바뀌어서 의도치 않은 결과가 나타날 수 있다. 생략 가능한 경우도 적어주자. 어차피 옵티마이저가 최적화를 한다.
    - 인덱스를 사용한 정렬이 가능한 이유는 B-Tree 인덱스가 키 값으로 정렬돼 있기 때문이다. 또한 조인이 네스티드-루프 방식으로 실행되기 때문에 조인 때문에 드라이빙 테이블의 인덱스 읽기 순서가 흐트러지지 않는다는 것이다. 하지만 조인이 사용된 쿼리의 실행 계획에 조인버퍼가 사용되면 순서가 흐트러질 수 있기 때문에 주의해야 한다.

- 드라이빙 테이블만 정렬
    - 일반적으로 조인이 수행되면 결과 레코드의 건수가 몇 배로 불어난다. 그래서 조인을 실행하기 전에, 첫 번째 테이블의 레코드를 먼저 정렬한 다음 조인을 실행하는 것이 정렬의 차선책이 될 것이다. 이 방법은 조인에서 첫 번째 읽히는 테이블(드라이빙 테이블)의 칼럼만으로 ORDER BY 절이 작성돼야 한다.

    ![image](https://user-images.githubusercontent.com/37579660/101337243-c67db180-38be-11eb-9b6f-eea67a156b42.png)

    - WHERE 절의 조건이 다음 두 가지 조건을 갖추고 있기 때문에 옵티마이저는 employees 테이블을 드라이빙 테이블로 선택할 것이다.
    1. WHERE 절의 검색 조건 emp_no BETWEEN 100001 AND 100010은 employees 테이블의 프라이머리 키를 이용해 검색하면 작업량을 줄일 수 있다.
    2. 드리븐 테이블의 조인 칼럼인 emp_no 칼럼에 인덱스가 있다.
    - 검색은 인덱스 레인지 스캔으로 처리할 수 있지만 ORDER BY 절에 명시된 칼럼은 employees 테이블의 프라이머리 키와 전혀 연관이 없으므로 인덱스를 이용한 정렬은 불가능하다. 그런데 ORDER BY 절의 정렬 기준 칼럼이 드라이빙 테이블에 포함된 칼럼임을 알 수 있다. 옵티마이저는 드라이빙 테이블만 검색해서 정렬을 먼저 수행하고 그 결과와 salaries테이블을 조인한 것이다.
    - 이 과정을 다시 풀어서 설명해보자
        1. 인덱스를 이용해 emp_no BETWEEN 100001 AND 100010 조건을 만족하는 9건을 검색
        2. 검색 결과를 last_name 칼럼으로 정렬을 수행 (Filesort)
        3. 정렬된 결과를 순서대로 읽으면서 salaries 테이블과 조인을 수행해서 86건의 최종 결과를 가져옴.

        ![image](https://user-images.githubusercontent.com/37579660/101337235-c382c100-38be-11eb-90ae-21fc9cb002c1.png)

- 임시 테이블을 이용한 정렬
    - 쿼리가 여러 테이블을 조인하지 않고, 하나의 테이블로부터 SELECT해서 정렬하는 경우라면 임시 테이블이 필요하지 않다. 하지만 2개 이상의 테이블을 조인해서 그 결과를 정렬해야 한다면 임시 테이블이 필요할 수도 있다. 위에서 살펴본 "드라이빙 테이블만 정렬"은 2개 이상의 테이블이 조인되며넛 정렬이 실행되지만 임시 테이블을 사용하지 않는다. 하지만 그 밖의 패턴의 쿼리에서는 항상 조인의 결과를 임시 테이블에 저장하고, 그 결과를 다시 정렬하는 과정을 거친다. 이 방법은 정렬의 3가지 방법 가운데 정렬해야 할 레코드 건수가 가장 많아지기 때문에 가장 느린 정렬 방법이다. 다음 쿼리는 위의 드라이빙 테이블만 정렬에서 살펴본 예제와 ORDER BY 절의 칼럼만 제외하고 같은 쿼리다. 이 쿼리도 위의 이유와 같이 employees 테이블이 드라이빙 테이블로 사용되며, salaries 테이블이 드리븐 테이블로 사용될 것이다.

        ![image](https://user-images.githubusercontent.com/37579660/101337249-c7aede80-38be-11eb-809e-b2a91d6190b6.png)

    - 하지만 이번 쿼리는 ORDER BY 절의 정렬 기준 칼럼이 드라이빙 테이블이 아니라 드리븐 테이블에 있는 칼럼이다. 즉 정렬이 수행되기 전에 반드시 salaries 테이블을 읽어야 하므로 이 쿼리는 반드시 조인된 데이터를 가지고 정렬할 수밖에 없다.

    ![image](https://user-images.githubusercontent.com/37579660/101337257-c978a200-38be-11eb-9d8d-1e61f32490b0.png)

    - 실행 계획을 보면 Extra 칼럼에 Using teporary; Using filesort 라는 코멘트가 표시된다. 이는 조인의 결과를 임시 테이블에 저장하고, 그 결과를 다시 정렬 처리했음을 의미한다.

    ![image](https://user-images.githubusercontent.com/37579660/101337267-caa9cf00-38be-11eb-99b1-16dfc627f73e.png)

- 정렬방식의 성능 비교
    - 웹 서비스용 쿼리에서는 ORDER BY와 함께 LIMIT가 거의 필수적으로 사용되는 경향이 있다. 일반적으로 LIMIT는 테이블이나 처리 결과의 일부만 가져오기 때문에 마스 서버가 처리해야 할 작업량을 줄이는 역할을 한다. 그런데 ORDER BY나 GROUP BY와 같은 작업은 WHERE 조건을 만족하는 레코드를 LIMIT 건수만큼만 가져와서는 처리될 수 없다. 우선 조건을 만족하는 레코드를 모두 가져와서 정렬을 수행하거나 그루핑 작업을 실행해야만 비로소 LIMIT로 건수 제한을 할 수 있기 때문이다. WHERE 조건이 아무리 인덱스를 잘 활용하도록 튜닝해도 잘못된 ORDER BY나 GROUP BY 때문에 쿼리가 느려지는 경우가 자주 발생한다.
    - 이제는 쿼리에서 인덱스를 사용하지 못하는 정렬이나 그루핑 작업이 왜 느리게 작동할 수밖에 없는지를 살펴볼 것이다. 이를 위해 쿼리가 처리되는 방법을 스트리밍 처리와 버퍼링 처리라는 2가지 방식으로 구분해볼 예정이다.
        - 스트리밍 방식 : 서버 쪽에서 처리해야 할 데이터가 얼마나 될지에 관계 없이 조건에 일치하는 레코드가 검색될 때마다 바로바로 클라이언트로 전송해주는 방식을 의미한다. 이 방식으로 쿼리를 처리할 경우 클라이언트는 쿼리를 요청하고 곧바로 원했던 첫 번째 레코드를 전달받을 것이다. 물론 가장 마지막의 레코드는 언제 받을지 알 수 없지만 이는 그다지 중요하지 않다. 쿼리가 이 방식으로 처리된다면 클라이언트는 마스 서버가 일치하는 레코드를 찾는 즉시 전달 받기 때문에 동시에 데이터의 가공 작업을 진행할 수 있다. 웹서비스와 같은 OLTP 환경에서는 쿼리의 요청에서부터 첫 번째 레코드를 전달받게 되기까지의 응답 시간이 중요하다. 스트리밍 방식으로 처리되는 쿼리는 쿼리가 얼마나 많은 레코드를 조회하느냐에 상관없이 빠른 응답 시간을 보장해 준다.
        또한 LIMIT와 같은 건수를 제한하는 조건들은 쿼리의 전체 실행 시간을 상당히 줄여줄 수 있다. 매우 큰 테이블을 아무런 조건 없이 SELECT만 해 보면 첫 번째 레코드는 아주 빨리 가져온다는 사실을 알 수 있다. 물론 서버에서는 쿼리가 아직 실행되고 있는 도중이라도 말이다. 인것은 풀 테이블 스캔의 결과가 아무런 버퍼링 처리나 필터링 과정 없이 바로 클라이언트로 스트리밍되기 때문이다. 이 쿼리에 LIMIT 조건을 추가하면 전체적으로 가져오는 레코드 건수가 줄어들기 때문에 마지막 레코드를 가져오기까지의 시간을 상당히 줄일 수 있다.

            ![image](https://user-images.githubusercontent.com/37579660/101337464-0e9cd400-38bf-11eb-957e-650aac741719.png)

        - 버퍼링 방식 : ORDER BY나 GROUP BY와 같은 처리는 쿼리의 결과가 스트리밍되는 것을 불가능하게 한다. 우선 WHERE 조건에 일치하는 모든 레코드를 가져온 후, 정렬하거나 그루핑해서 차례대로 보내야 하기 때문이다. 마스 서버에서는 모든 레코드를 검색하고 정렬 작업을 하는 동안 클라이언트는 아무것도 하지 않고 기다려야 하기 때문에 응답 속도가 느려지는 것이다. 이 방식을 스트리밍의 반대 표현으로 버퍼링이라고 표현해 본 것이다. 이 방식은 결과를 모아서 마스 서버에서 일괄적으로 가공해야 하므로 모든 결과를 스토리지 엔진으로부터 가져올 때까지 기다려야 한다. 그래서 버퍼링 방식으로 처리되는 쿼리는 LIMIT 처럼 건수를 제한하는 조건이 있어도 성능 향상에 별로 도움이 되지 않는다. 네트워크로 전송되는 레코드의 건수를 줄일 수는 있지만 마스 서버가 해야하는 작업량에는 그다지 변화가 없기 때문이다.

            ![image](https://user-images.githubusercontent.com/37579660/101337467-0fce0100-38bf-11eb-92c7-5fa4988357c7.png)

        - 비록 마스 서버를 사용하여 스트리밍 방식으로 정보를 가져오더라도 JDBC를 사용할 경우에는 결과적으로 JDBC 자체의 버퍼에 담아두고 마지막 레코드가 전달될 때까지 기다렸다가 모든 결과를 전달받으면 그때서야 클라이언트의 애플리케이션에 반환한다. 즉 JDBC 라이브러리가 버퍼링을 하는 것이다. 그 이유는 이 방식이 전체 처리량(Throughput)에서 뛰어나기 때문이다. JDBC라이브러리와 마스 서버가 대화형으로 데이터를 주고받는 것이 아니라 마스 서버는 데이터의 크기에 관계없이 무조건 보내고 JDBC는 마스 서버로부터 전송되는 데이터를 받아서 저장만 하므로 불필요한 네트워키 요청이 최소화되기 때문에 전체 처리량이 뛰어난 것이다. 하지만 이는 디폴트 설정이고 바꿀 수 있다.
    - ORDER BY의 처리 방식 가운데 인덱스를 사용한 정렬 방식만 스트리밍 형태이다. 나머지는 모두 버퍼링된 후에 정렬된다. 즉 인덱스를 사용한 정렬 방식은 LIMIT로 제한된 건수만큼만 읽으면서 바로바로 클라이언트로 결과를 전송해줄 수 있다. 하지만 인덱스를 사용하지 못하는 경우의 처리는 필요한 모든 레코들르 디스크로부터 읽어서 정렬한 후에야 로소 LIMIT로 제한된 건수만큼 잘라서 클라이언트로 전송해줄 수 있음을 의미한다.
    - 실제 조인과 함께 ORDER BY 그리고 LIMIT이 함께 사용될 경우를 살펴보자.

        ![image](https://user-images.githubusercontent.com/37579660/101337470-10ff2e00-38bf-11eb-86dc-ea74fac32a64.png)

        ![image](https://user-images.githubusercontent.com/37579660/101337473-12305b00-38bf-11eb-9fe5-aa28705c725f.png)

        어느 테이블이 먼저 드라이빙되어 조인되는지도 중요하지만 어떤 정렬 방식으로 처리되는지는 더 큰 성능 차이를 만든다. 가능하다면 인덱스를 사용한 정렬로 유도하고 그렇지 못하다면 최소한 드라이빙 테이블만 정렬해도 되는 수준으로 유도하는 것도 좋은 튜닝 방법이라고 할 수 있다.

        ![image](https://user-images.githubusercontent.com/37579660/101337475-12c8f180-38bf-11eb-8864-78d29355b672.png)

- 정렬 관련 상태 변수
    - 마스 서버는 처리하는 주요 작업에 대해서는 해당 작업의 실행 횟수를 상태 변수로 저장하고 있다. 정렬과 관련해서도 지금까지 몇 건의 레코드나 정렬 처리를 수행했는지, 소트 버퍼 간의 병합 작업은 몇 번이나 발생했는지 등을 다음과 같은 명령으로 확인해 볼 수 있다.

        ![image](https://user-images.githubusercontent.com/37579660/101337479-13fa1e80-38bf-11eb-91ea-e8eef83ab380.png)

    - 이를 확인하여 마스 서버가 지금까지 처리한 정렬 작업의 내용을 어느정도 이해할 수 있다.
    - Srot_merge_passes : 멀티 머지 처리 횟수
    - Sort_range : 인덱스 레인지 스캔을 통해 검색된 결과에 대한 정렬 작업 횟수
    - Sort_scan : 풀 테이블 스캔을 통해 검색된 결과에 대한 정렬 작업 횟수. 위의 값과 이 값은 정렬 작업 횟수를 누적하고 있는 상태 값이다.
    - Sort_rows : 지금까지 정렬한 전체 레코드 건수
    - 이 내용을 바탕으로 쿼리문의 정렬 내용을 파악해보면

        ![image](https://user-images.githubusercontent.com/37579660/101337485-152b4b80-38bf-11eb-89c5-24eca437de12.png)


### GROUP BY 처리

- 이것도 ORDER BY와 같이 쿼리가 스트리밍된 처리를 할 수 없게 하는 요소 중 하나다. HAVING 절을 사용할 수 있는데 이는 GROUP BY 절의 결과에 대한 필터링 역할을 수행한다. 일반적으로 GROUP BY 처리 결과는 임시 테이블이나 버퍼에 존재하는 값을 필터링하는 역할을 수행한다. GROUP BY에 사용된 조건은 인덱스를 사용해서 처리될 수 없으므로 HAVING 절을 튜닝하려고 인덱스를 생성하거나 다른 방법을 고민할 필요는 없다.
- GROUP BY 작업도 인덱스를 사용하는 경우와 그렇지 못한 경우로 나눠볼 수 있다. 사용할 때는 인덱스를 차례대로 이용하는 인덱스 스캔 방법과 인덱스를 건너 뛰면서 읽는 루스 인덱스 스캔이라는 방법으로 나뉜다. 그리고 인덱스를 사용하지 못하는 쿼리에서 GROUP BY 작업은 임시 테이블을 사용한다.

- 인덱스 스캔을 이용하는 GROUP BY (타이트 인덱스 스캔)
    - ORDER BY 와 마찬가지로 조인의 드라이빙 테이블에 속한 칼럼만 이용해 그룹핑할 때 GROUP BY 칼럼으로 이미 인덱스가 있다면 그 인덱스를 차례대로 읽으면서 그룹핑 작업을 수행하고 그 결과로 조인을 처리한다.  GROUP BY가 인덱스를 사용해서 처리된다 하더라도 그룹 함수 등의 그룹값을 처리해야 해서 임시 테이블이 필요할 때도 있다. GROUP BY가 인덱스를 통해 처리되는 쿼리는 이미 정렬된 인덱스를 읽는 것이므로 추가적인 정렬 작업은 필요하지 않다. 이런 그룹핑 방식을 사용하는 쿼리의 실행 계획에서는 Extra 칼럼에 별도로 GROUP BY 관련 코멘트나 임시 테이블이나 정렬 관련 코멘트(Using temporary, Using filesort)가 표시되지 않는다.
- 루스 인덱스 스캔을 이용하는 GROUP BY
    - 루스 인덱스 스캔 방식은 인덱스의 레코드를 건너뛰면서 필요한 부분만 가져오는 것을 의미하는데, 실행 계획의 Using index for group-by 코멘트를 설명하면서 한번 언급한 적이 있다. 루스 인덱스 스캔을 사용하는 다음 예제를 한번 살펴보자.

        ![image](https://user-images.githubusercontent.com/37579660/101337617-3db34580-38bf-11eb-909b-0a1f1ef58330.png)

        ![image](https://user-images.githubusercontent.com/37579660/101337622-3ee47280-38bf-11eb-97b3-c22da939de13.png)

        정리하면 우선 인덱스 걸려있고 GROUP BY 걸려있는 emp_no를 기준으로 본다는거 아닐까 싶다.

    - 루스 인덱스 스캔은 단일 테이블에 대해 수행되는 GROUP BY 처리에만 사용할 수 있다. 또한 프리픽스 인덱스는 루트 인덱스 스캔을 사용할 수 없다. 인덱스 레인지 스캔에서는 유니크한 값의 수가 많을수록 성능이 향상되는 반면 루스 인덱스 스캔에서는 인덱스의 유니크한 값의 수가 적을수록 성능이 향상된다. 즉 루스 인덱스 스캔은 분포도가 좋지 않은 인덱스일수록 더 빠른 결과를 만들어낸다. 그리고 별도의 임시 테이블이 필요하지 않다.
    - 루스 인덱스 스캔이 사용될 수 있을지 없을지 판단하는 것은 WHERE 절의 조건이나 ORDER BY 절이 인덱스를 사용할 수 있을지 없을지 판단하는 것보다는 더 어렵다. 그래도 우리는 여러 패턴의 쿼리를 살펴보고, 루스 인덱스 스캔을 사용할 수 있는지 없는지 판별하는 연습을 해보자. 우선 컬럼 1,2,3으로 생성된 tb_test테이블을 가정해보자. 다음 쿼리들은 루스 인덱스 스캔을 사용할 수 있는 쿼리다.

        ![image](https://user-images.githubusercontent.com/37579660/101337633-4146cc80-38bf-11eb-8059-8ad635db28af.png)

        다음은 사용할 수 없는 쿼리다.

        ![image](https://user-images.githubusercontent.com/37579660/101337628-40159f80-38bf-11eb-9907-c89d58542758.png)

- 임시 테이블을 사용하는 GROUP BY
    - GROUP BY의 기준 칼럼이 드라이빙 테이블에 있든 드리븐 테이블에 있든 관계 없이 인덱스를 전혀 사용하지 못할 때는 이 방식으로 처리된다.

        ![image](https://user-images.githubusercontent.com/37579660/101337636-4277f980-38bf-11eb-9a5a-ff3c5829516e.png)

        ![image](https://user-images.githubusercontent.com/37579660/101337638-43a92680-38bf-11eb-964b-a5803d679e9c.png)

### DISTINCT 처리

- 특정 칼럼의 유니크한 값만을 조회하려면 SELECT 쿼리에 DISTINCT를 사용한다. DISTINCT는 MIN, MAX, COUNT와 같은 집합 함수와 함께 사용되는 경우와 아닌 경우 두가지로 구분된다. 그 이유는 DISTINCT 키워드가 미치는 영향의 범위가 달라지기 때문이다. 그리고 집합함수와 같이 DISTINCT가 사용되는 쿼리의 실행 계획에서 DISTINCT 처리가 인덱스를 사용하지 못할 때는 항상 임시 테이블이 필요하다. 하지만 실행 계획의 Extra 칼럼에는 Using temporary가 출력되지 않는다.

- SELECT DISTINCE
    - 단순히 SELECT 되는 레코드 중에서 유니크한 레코드만 가져오고자 하면 SELECT DISTINCE 형태의 쿼리 문장을 사용한다. 이 경우에는 GROUP BY와 거의 같은 방식으로 처리된다. 단지 차이는 정렬이 보장되지 않는 다는 것이다. 다음의 두 쿼리는 정렬 관련 부분을 제외하고는 같은 작업을 수행한다. 두 쿼리는 모두 인덱스를 이용하기에 부가적인 정렬작업이 필요하지 않고 완전히 같은 쿼리다.

    ```java
    SELECT DISTINCT emp_no FROM salaries;
    SELECT emp_no FROM salaries GROUP BY emp_no;
    ```

    - 다만 인덱스를 이용하지 못하는 DISTINCT는 정렬을 보장하지 않는다.

    - DISTINCT를 사용할 때의 실수는 DISTINCT는 SELECT하는 레코드를 유니크하게 SELECT하는 것이지 칼럼을 유니크하게 조회하는 것이 아니라는 것이다. 즉 다음 쿼리에서 SELECT하는 결과는 first_name만 유니크한 것이 아니라 (first_name + last_name) 전체가 유니크한 레코드를 가져오는 것이다.

    ```java
    SELECT DISTINCE first_name, last_name FROM employees;
    ```

    - 아래와 같이 사용하는 경우도 있지만 마스 서버는 DISTINCT 뒤의 괄호를 의미 없다고 생각하고 제거한다.
    그래서 위의 쿼리와 같게 된다.

    ```java
    SELECT DISTINCE (first_name), last_name FROM employees;
    ```

    - 절대로 SELECT하는 여러 칼럼 중에서 일부 칼럼만 유니크하게 조회하는 방법은 없다. 단 뒤에서 설명하는 집합 함수 내에서 사용된 경우는 조금 다르다.

- 집합 함수와 함께 사용된 DISTINCT
    - COUNT, MAX, MIN과 같은 집합함수 내에서 DISTINCT 키워드가 사용될 경우에는 위에서 설명한 것과 달리 해석된다. 집합함수가 없는 SELECT 쿼리에서 DISTINCT는 조회하는 모든 칼럼의 조합이 유니크한 것들만 가져온다. 하지만 내에서 사용된 DISTINCT는 그 집합 함수의 인자로 전달된 칼럼 값들 중에서 중복을 제거하고 남은 값만을 가져온다.

    ```java
    EXPLAIN
    SELECT COUNT(DISTINCT s.salary)
    FROM employees e, slalaries s
    WHERE e.emp_no=s.emp_no
    AND e.emp_no BETWEEN 100001 AND 100100;
    ```

    - 이 쿼리는 내부적으로는 COUNT(DISTINCT s.salary)를 처리하기 위해 임시 테이블을 사용한다. 하지만 이 쿼리의 실행 계획에는 임시 테이블을 사용한다는 메시지는 표시되지 않는다. 버그처럼 보이지만 정말 표시되지 않는다.

        ![image](https://user-images.githubusercontent.com/37579660/101337774-6f2c1100-38bf-11eb-8843-e014a997b620.png)

    - employees 테이블과 salaries 테이블을 조인한 결과에서 salary 칼럼의 값만 저장하기 위한 임시 테이블을 만들어서 사용한다. 이때 임시 테이블의 salary 칼럼에는 유니크 인덱스가 생성되기 때문에 레코드 건수가 많아진다면 상당히 느려질 수 있는 형태의 쿼리다.
    - 위의 쿼리에 COUNT를 하나 더 추가해보자.

    ```java
    EXPLAIN
    SELECT COUNT(DISTINCT s.salary), COUNT(DISTINCE e.last_name)
    FROM employees e, slalaries s
    WHERE e.emp_no=s.emp_no
    AND e.emp_no BETWEEN 100001 AND 100100;
    ```

    - 이 경우 s.salary 칼럼의 값을 저장하는 임시 테이블과 e.last_name 칼럼의 값을 저장하는 또 다른 임시 테이블 총 2개의 임시 테이블을 이용한다. 그리고 DISTINCT 처리를 위해 인덱스를 이용할 수 없어서 임시 테이블이 필요하다.
    - 아래의 쿼리는 인덱스된 칼럼에 대해 DISTINCT 처리를 수행할 때는 인덱스를 풀 스캔하거나 레인지 스캔하면서 임시 테이블 없이 최적화된 처리를 수행할 수 있다.

    ```java
    SELECT COUNT(DISTINCE emp_no) FROM employees;
    SELECT COUNT(DISTINCE emp_no) FROM dept_emp GROUP BY dept_no;
    ```

    ![image](https://user-images.githubusercontent.com/37579660/101337781-705d3e00-38bf-11eb-9e3c-887b78a5758b.png)

### 임시 테이블

- 마스 엔진이 스토리지 엔진으로부터 받아온 레코드를 정렬하거나 그루핑할 때는 내부적인 임시 테이블을 사용한다. 내부적이라는 단어가 포함된 것은 여기서 이야기하는 임시 테이블은 CREATE TEMPORARY TABLE로 만든 임시 테이블과는 다르기 때문이다. 일반적으로 마스 엔진이 사용하는 임시 테이블은 처음에는 메모리에 생성됐다가 테이블의 크기가 커지면 디스크로 옮겨진다. 물론 특정 예외 케이스에는 메모리를 거치지 않고 바로 디스크에 임시 테이블이 만들어지기도 한다. 원본 테이블의 스토리지 엔진과 관계없이 임시 테이블이 메모리를 사용할 때는 MEMORY 스토리지 엔진을 사용하며, 디스크에 저장될 때는 MyISAM 스토리지 엔진을 이용한다.
마스 엔진이 내부적인 가공을 위해 생성하는 임시 테이블은 다른 세션이나 다른 쿼리에서는 볼 수 없으며 사용하는 것도 불가능하다. 그리고 내부적인 임시 테이블은 쿼리의 처리가 완료되면 자동으로 삭제된다.

- 임시 테이블이 필요한 쿼리
    - 내부 임시 테이블이 필요한 쿼리는 마스 엔진에서 별도의 데이터 가공 작업을 필요로하는 쿼리. 그리고 인덱스를 사용하지 못할 경우에도 이런 경우가 많다.
        - ORDER BY와 GROUP BY에 명시된 칼럼이 다른 쿼리
        - ORDER BY나 GROUP BY에 명시된 칼럼이 조인의 순서상 첫번째 테이블이 아닌 쿼리
        - DISTINCT와 ORDER BY가 동시에 쿼리에 존재하는 경우 또는 DISTINCT가 인덱스로 처리되지 못하는 쿼리
        - UNION이나 UNION DISTINCT가 사용된 쿼리(select_type 칼럼이 UNION RESULT인 경우)
        - UNION ALL이 사용된 쿼리(select_type 칼럼이 UNION RESULT인 경우)
        - 쿼리의 실행 계획에서 select_type이 DERIVED인 쿼리
    - 어떤 쿼리의 실행 계획에서 임시 테이블을 사용하는지는 Extra 칼럼에 Using temporary라는 키워드가 표시되는지 확인하면 된다. 하지만 이 키워드가 표시되지 않을 때에도 임시 테이블을 사용할 수 있다. 위의 예시에서 마지막 3개 패턴이 그런 예이다. 첫번째부터 네번째까지는 유니크 인덱스를 가지는 내부 임시 테이블이 만들어진다. 그리고 다섯번째 여섯번째 쿼리 패턴은 유니크 인덱스가 없는 내부 임시 테이블이 생성된다. 일반적으로 유니크 인덱스가 있는 내부 임시 테이블은 그렇지 않은 쿼리보다 상당히 처리 성능이 느리다.

- 임시 테이블이 디스크에 생성되는 경우(MyISAM 스토리지 엔진을 사용)
    - 내부 임시 테이블은 기본적으로는 메모리상에 만들어지지만 다음과 같은 조건을 만족하면 메모리에 임시 테이블을 생성할 수 없으므로 디스크상에 MyISAM 테이블로 만들어진다.
        - 임시 테이블에 저장해야 하는 내용 중 BLOB나 TEXT와 같은 대용량 칼럼이 있는 경우
        - 임시 테이블에 저장해야 하는 레코드의 전체 크기나 UNIONdlsk UNION ALL에서 SELECT되는 칼럼 중에서 길이가 512바이트 이상인 크기의 칼럼이 있는 경우
        - GROUP BY나 DISTINCT 칼럼에서 512바이트 이상인 크기의 칼럼이 있는 경우
        - 임시 테이블에 저장할 데이터의 전체 크기(바이트 크기)가 tmp_table_size 또는 max_heap_table_size 시스템 설정 값보다 큰 경우
    - 첫 번째부터 세 번째까지는 처음부터 디스크에 MyISAM스토리지 엔진을 사용해서 내부 임시 테이블이 만들어진다. 하지만 마지막은 처음에는 MEMORY 스토리지 엔진을 이용해 메모리에 내부 임시 테이블이 생성되지만 테이블의 크기가 시스템 설정 값을 넘어서는 순간 디스크의 MyISAM 테이블로 변환된다.

- 임시 테이블 관련 상태 변수
    - 실행 계획상에서 Using temporary가 표시되면 임시 테이블을 사용했다는 사실을 알 수 있다. 하지만 임시 테이블이 메모리에서 처리됐는지 디스크에서 처리됐는지는 알 수 없으며, 몇 개의 임시 테이블이 사용됐는지도 알 수 없다. Using temporary가 한번 표시됐다고 해서 임시 테이블을 하나만 사용했다는 것을 의미하지 않는다. 임시 테이블이 디스크에 생성됐는지 메모리에 생성됐는지 파악하려면 마스 서버의 상태변수를 확인해보면 된다. ⇒ SHOW SESSION STATUS LIKE 'Created_tmp%';

        ![image](https://user-images.githubusercontent.com/37579660/101337785-70f5d480-38bf-11eb-8ddf-f9ed45a4024f.png)

    - 내용을 보면 쿼리를 실행하기 전에 SHOW SESSION STATUS LIKE 'Created_tmp%'; 명령으로 임시 테이블의 사용 현황을 먼저 확인해 둔다. 그리고 SELECT 쿼리를 실행한 후, 다시 상태 조회 명령을 실행해 보면 된다. 예제의 두 상태 변수가 누적하고 있는 값의 의미는 다음과 같다.
        - Created_tmp_tables : 쿼리의 처리를 위해 만들어진 내부 임시 테이블의 개수를 누적하는 상태 값. 이 값은 내부 임시 테이블이 메모리에 만들어졌는지 디스크에 만들어졌는지를 구분하지 않고 모두 누적한다.
        - Created_tmp_disk_tables : 디스크에 내부 임시 테이블이 만들어진 개수만 누적해서 가지고 있는 상태 값.
    - 이 두 값을 이용해서 3-2=1이라는 값이 도출되고 그 내용은 임시 테이블이 디스크에 만들어졌음을 알 수 있다.

- 임시 테이블 관련 주의사항
    - 레코드 건수가 많지 않으면 내부 임시 테이블이 메모리에 생성되고 마스의 서버의 부하에 크게 영향을 미치지는 않는다. 성능상의 이슈가 될만한 부분은 내부 임시 테이블이 MyISAM 테이블로 디스크에 생성되는 경우다.

    ```java
    SELECT * FROM employees GROUP BY last_name ORDER BY first_name;
    ```

    - 이 쿼리는 GROUP BY와 ORDER BY 칼럼이 다르고, last_name 칼럼에 인덱스가 없기에 임시 테이블과 정렬 작업까지 수행해야 하는 가장 골칫거리가 되는 쿼리 형태다.

    ![image](https://user-images.githubusercontent.com/37579660/101337789-72270180-38bf-11eb-8823-afd51ef5da9a.png)

    - 위의 상황에서 디스크에 임시 테이블이 저장된 경우라면 30만 건은 부하가 발생할 여지가 크다는 것이다. 그렇기에 가능한한 인덱스를 이용해 처리하고, 처음부터 임시 테이블이 필요하지 않게 만드는 것이 가장 좋다. 만약 이렇게 하기 어렵다면 내부 임시 테이블이 메모리에만 저장될 수 있게 가공 대상 코드를 적게 만드는 것이 좋다. 하지만 가공해야 할 데이터를 줄일 수 없다고 해서 tmp_table_size 또는 max_heap_table_size 시스템 설정 변수를 무조건 크게 설정하면 마스 서버가 사용할 여유 메모리를 내부 임시 테이블이 모두 사용해버릴 수도 있으므로 주의해야 한다.
    - 임시 테이블이 MEMORY 테이블로 물리 메모리에 생성되는 경우에도 주의해야 할 사항이 있다. MEMORY 테이블의 모든 칼럼은 고정 크기 칼럼이라는 점이다. 만약, 위이 예제 쿼리에서 first_name 칼럼이 VARCHAR(512)라 가정하자. 실제 메모리 테이블에서 first_name 칼럼이 차지하는 공간은 512*3 바이트가 될 것이다. 실제 first_name 칼럼의 값이 1글자이든 2글자이든 관계 없이, 테이블에 정의된 크기만큼 메모리 테이블에서 공간을 차지한다는 것이다. 이러한 임시 테이블의 저장 방식 때문에 SELECT하는 컬럼은 최소화하고, 칼럼의 데이터 타입 선정도 가능한 한 작게 해주는 것이 좋다.

### 테이블 조인

- 조인의 종류
    - INNER JOIN과 OUTER JOIN으로 구분할 수 있꼬 아우터는 다시 LEFT OUTER JOIN RIGHT OUTER JOIN 그리고 FULL OUTER JOIN으로 구분할 수 있다. 그리고 조건에 따라 NATURAL JOIN과 CROSS JOIN(FULL, CARTESIAN JOIN)으로 구분할 수 있다.
    - 조인의 처리에서 어느 테이블을 먼저 읽을지를 결정하는 것은 상당히 중요하며, 그에 따라 처리할 작업량이 상당히 달라진다. 이너조인은 어느 테이블을 먼저 읽어도 결과가 달라지지 않으므로 마스 옵티마이저가 조인의 순서를 조절해서 다양한 방법으로 최적화를 수행할 수 있다. 하지만 아우터 조인은 아우터가 되는 테이블을 먼저 읽어야 하기 때문에 조인 순서를 옵티아미저가 선택할 수 없다.

- JOIN (INNER JOIN)
    - 일반적으로 조인이라 함은 이너 조인을 지칭하는데 별도로 아우터 조인과 구분할 때 이너 조인이라고도 한다. 마스에서 조인은 네스티드-루프 방식만 지원한다. 이는 일반적으로 프로그램을 작성할 때 두 개의 FOR나 WHILE과 같은 반복 루프 문장을 실행하는 형태로 조인이 처리되는 것을 의미한다.

        ![image](https://user-images.githubusercontent.com/37579660/101337795-73582e80-38bf-11eb-9a7b-89a3f0294cf1.png)

    - 두개의 반복문으로 두개의 테이블을 조건에 맞게 연결해주는 작업이다. 두개의 FOR 문 중 바깥쪽을 아우터 테이블이라고 하며 안쪽을 이너 테이블이라고 표현한다. 또한 아우터 테이블은 이너 테이블보다 먼저 읽어야 하며, 조인에서 주도적인 역할을 한다고 해서 드라이빙 테이블이라고도 한다. 이너 테이블은 조인에서 끌려가는 역할을 한다고 해서 드리븐 테이블이라고도 한다.
    - 중첩된 반복 루프에서 최종적으로 선택될 레코드가 안쪽 반복 루프에 의해 결정되는 경우 이너 조인이라고 한다. 즉 두 개의 반복 루프를 실행하면서 이너 테이블에 IF (record1.join_column == record2.join_column) 조건을 만족하는 레코드만 조인의 결과로 가져온다.

        ![image](https://user-images.githubusercontent.com/37579660/101337799-74895b80-38bf-11eb-8613-ef46b7228641.png)

    - employees가 드라이빙 테이블이며 salaries는 드리븐 테이블이다. 그리고 이너조인이다. emp_no가 100002인 레코드는 salaries 테이블에 존재하지 않는다는 것을 알게 되고, 이렇게 짝을 찾지 못하는 레코드는 (드라이빙 테이블에만 존재하는 레코드) 조인 결과에 포함되지 않는다.

- OUTER JOIN

    ![image](https://user-images.githubusercontent.com/37579660/101337803-75ba8880-38bf-11eb-9cf9-e4f18917b4bb.png)

    - 위 코드에서 이너 테이블에 일치하는 레코드가 있으면 이너조인과 같은 결과를 만들어내지만 이너 테이블에 조건에 만족하는 레코드가 없는 경우에는 이너테이블의 칼럼을 모두 NULL로 채워서 가져온다. 즉 이너 조인에서는 일치하는 레코드를 찾지 못했을 때는 아우터 테이블의 결과를 모두 버리지만 아우터 조인에서는 아우터 테이블의 결과를 버리지 않고 그대로 결과에 포함한다. 이너 테이블이 조인의 결과에 전혀 영향을 미치지 않고 아우터 테이블의 내용에 따라 조인의 결과가 결정되는 것이 아우터 조인의 특징이다. 물론 아우터 테이블과 이너 테이블과 관계 (1:M 등등)에 의해 최종 결과 레코드 건수가 늘어날 수는 있지만, 아우터 테이블의 레코드가 이너 테이블에 일치하는 레코드가 없다고 해서 버려지지는 않는다.

    ![image](https://user-images.githubusercontent.com/37579660/101337804-76531f00-38bf-11eb-9453-6aae708fa923.png)

    - 위의 그림에서 emp_no가 100002번인 레코드는 salaries 테이블에서 일치하는 레코드를 찾지 못했다. 하지만 emp_no가 100002번인 레코드는 최종 아우터 조인의 결과에 포함된다. 물론 이때 salaries 테이블에는 일치하는 레코드가 없으므로 최종 결과의 salaries 테이블 칼럼은 NULL로 채워진다.

- 이 아우터 조인은 아우터 테이블이 조인의 왼쪽에 있는지 오른쪽에 있는지에 따라 LEFT OUTER JOIN과 RIGHT OUTER JOIN 그리고 FULL OUTER JOIN으로 다시 나뉜다.

![image](https://user-images.githubusercontent.com/37579660/101337809-781ce280-38bf-11eb-8118-a9c7ca48488c.png)

![image](https://user-images.githubusercontent.com/37579660/101337814-794e0f80-38bf-11eb-8484-1a4838c7ec54.png)

- 위의 두 쿼리는 각각 다른 아우터 조인을 사용했지만 결국 같은 처리 결과를 만들어내는 쿼리다. 둘 다 결국 처리 내용이 같으므로 혼동을 막기 위해 LEFT OUTER JOIN으로 통일해서 사용하는 것이 일반적이다.

- JOIN 키워드를 기준으로 왼쪽도 아우터 조인 오른쪽도 아우터 조인을 하고 싶은 경우 FULL OUTER JOIN 을 사용하면 되는데 마스에서는 이를 지원하지 않는다. 하지만 이너조인과 아우터조인을 섞어서 활용하면 이와 같은 역할을 하는 쿼리를 작성할 수 있다.

- LEFT OUTER JOIN에서는 쉽게 실수할 수 있는 부분들이 여러 가지 있다. 이를 더 알아보자
    - 마스 실행 계획은 이너 조인을 사용했는지, 아우터 조인을 사용했는지를 알려주지 않으므로 아우터 조인을 의도한 쿼리가 이너 조인으로 실행되지는 않는지 주의해야 한다. 아우터 조인에서 레코드가 없을 수도 있는 쪽의 테이블에 대한 조건은 반드시 레프트조인의 ON 절에 모두 명시하자. 그렇지 않으면 옵티마이저는 아우터 조인을 내부적으로 이너 조인으로 변형시켜서 처리해 버릴 수 있다. LEFT OUTER JOIN의 ON 절에 명시되는 조건은 조인되는 레코드가 있을 때만 적용된다. 하지만 WHERE 절에 명시되는 조건은 아우터 조인이나 이너 조인에 관계없이 조인된 결과에 대해 모두 적용된다. 그래서 아우터 조인으로 연결되는 테이블이 있는 쿼리에서는 가능하다면 모든 조건을 ON 절에 명시하는 습관을 들이는 것이 좋다.

```java
SELECT *
FROM employees e
	LEFT OUTER JOIN salaries s ON s.emp_no=e.emp_no
WHERE s.salary > 5000;
```

- 위 쿼리의 LEFT OUTER JOIN 절과 WHERE 절은 서로 충돌되는 방식으로 사용된 것이다. 아우터 조인으로 연결되는 테이블의 칼럼에 대한 조건이 ON 절에 명시되지 않고 WHERE 절에 명시 됐기 때문이다. 그래서 마스 서버는 이 쿼리를 최적화 단계에서 아래와 같은 쿼리로 변경하여 실행한다. 이는 본래 의도와 다른 결과를 반환한다.

```java
SELECT *
FROM employees e
	INNER JOIN salaries s ON s.emp_no=e.emp_no
WHERE s.salary > 5000;
```

이런 상황이 발생하기에 아래의 두가지 중 하나로 수정해야 의도한 바를 나타낼 수 있다.

```java
// 순수하게 아우터 조인으로 표현한 쿼리

SELECT *
FROM employees e
	LEFT OUTER JOIN salaries s ON s.emp_no=e.emp_no AND s.salary > 5000;

// 순수하게 이너 조인으로 표현한 쿼리

SELECT *
FROM employees e
  INNER JOIN salaries s ON s.emp_no=e.emp_no
WHERE s.salary > 5000;
```

LEFT OUTER JOIN이 아닌 쿼리에서는 검색 조건이나 조인 조건을 WHERE 절이나 ON 절 중에서 어느 곳에 명시해도 성능상의 문제나 결과의 차이가 나지 않는다. 

- 카테시안 조인
    - 다른 이름으로 FULL JOIN 혹은 CROSS JOIN이라고도 한다. 일반적으로는, 조인을 수행하기 위해 하나의 테이블에서 다른 테이블로 찾아가는 연결 조건이 필요하다. 하지만 카테시안 조인은 이 조인 조건 자체가 없이 2개 테이블의 모든 레코드 조합을 결과로 가져오는 조인 방식이다. 카테시안 조인은 조인이 되는 테이블의 레코드 건수가 1~2건 정도로 많지 않을 때라면 특별히 문제가 되지는 않는다. 하지만 레코드 건수가 많아지면 조인의 결과 건수가 기하급수적으로 늘어나므로 MySQL 서버 자체를 응답 불능 상태로 만들어버릴 수도 있다.
    - 조인의 양쪽 테이블이 모두 레코드 1건인 쿼리를 제외하면, 애플리케이션에서 사용되는 카테시안 조인은 의도하지 않았던 경우가 대부분이다. N개 테이블의 조인이 수행되는 쿼리에서는 반드시 조인 조건은 N-1개 또는 그 이상이 필요하며 모든 테이블은 반드시 1번 이상 조인 조건에 사용돼야 카테이산 조인을 피할 수 있다. 조인되는 테이블이 많아지고 조인 조건이 복잡해질수록 의도하지 않은 카테시안 조인이 발생할 가능성이 크기 때문에 주의해야 한다.

    ```java
    SELECT * FROM departments WHERE dept_no='d001';

    SELECT * FROM employees WHERE emp_no=1000001;

    SELECT d.*, e.*
    FROM departments d, employees e
    WHERE dept_no = 'd001' AND emp_no=1000001;
    ```

    - 또한 카테시안 조인은 레코드 한 건만 조회하는 여러 개의 쿼리를 하나의 쿼리로 모아서 실행하기 위해 사용되기도 한다. 위 예제의 첫 번째와 두 번째 쿼리는 각각 레코드 1건씩을 조회하지만 전혀 연관이 없다. 이 각각의 쿼리를 하나로 묶어서 실행하기 위해 세 번째 쿼리와 같이 하나의 쿼리로 두 테이블을 조인해서 한번에 결과를 가져오고 있다. 하지만 employees 테이블과 departments 테이블을 연결해주는 조인 조건은 없음을 알 수 있다. 위와 같이 2개의 쿼리를 하나의 쿼리처럼 빠르게 실행하는 효과를 얻을 수도 있다. 하지만 카테시안 조인으로 묶은 2개의 단위 쿼리가 반환하는 레코드가 항상 1건이 보장되지 않으면 아무런 결과도 못 가져오거나 또는 기대했던 것보다 훨씬 많은 결과를 받게될 수도 있으므로 주의하자.
    - SQL 표준에서 CROSS JOIN은 카테시안 조인과 같은 조인 방식을 의미하지만 MySQL에서 CROSS JOIN은 INNER JOIN과 같은 조인 방식을 의미한다. MySQL에서 CROSS JOIN을 사용하는 경우 INNER JOIN과 같이 ON 절이나 WHERE 절에 조인 조건을 부여하는 것이 가능하며, 이렇게 작성된 CROSS JOIN은 INNER JOIN과 같은 방식으로 작동한다. 그래서 MySQL에서 CROSS JOIN은 카테시안 조인이 될 수도 있고, 아닐 수도 있다. 다음 두 예제는 같은 결과를 만들어 낸다.

    ```java
    SELECT d.*, e.*
    FROM departments d
        INNER JOIN employees e ON d.emp_no=e.emp_no;

    SELECT d.*, e.*
    FROM departments d
        CROSS JOIN employees e ON d.emp_no=e.emp_no;
    ```

    - 사실 마스에서 카테시안 조인과 이너 조인은 문법으로 구분되는 것이 아니다. 조인으로 연결되는 조건이 적절히 있다면 이너 조인으로 처리되고, 연결 조건이 없다면 카테시안 조인이 된다. 그래서 둘을 크게 구별해서 사용할 필요는 없다.

- NATURAL JOIN
    - 마스에서 이너조인의 조건을 명시하는 방법은 여러가지가 있다.

    ```java
    SELECT *
    FROM employees e, salaries s
    WHERE e.emp_no=s.emp_no;

    SELECT *
    FROM employees e
        INNER JOIN salaries s ON s.emp_no=e.emp_no;

    SELECT *
    FROM employees e
        INNER JOIN salaries s USING (emp_no);
    ```

    - 위의 세 쿼리는 표기법의 차이가 있을 뿐 같은 쿼리다. 세번째의 USING (emp_no)은 두 번째의 ON s.emp_no=e.emp_no와 같은 의미로 사용된다. 다만 USING 키워드는 조인되는 두 테이블의 조인 칼럼이 같은 이름을 가지고 있을 때만 사용할 수 있다. 여기서 살펴볼 NATURAL JOIN 또한 이너조인과 같은 결과를 가져오지만 표현 방법이 조금 다른 조인 방법 중 하나다. 아래를 통해 더 살펴보자.

    ```java
    SELECT *
    FROM employees e
    	NATURAL JOIN salaries s;
    ```

    - 위의 예제 쿼리도 employees 테이블의 emp_no 칼럼과 salaries 테이블의 emp_no 칼럼을 조인하는 쿼리다. NATURAL JOIN은 employees 테이블에 존재하는 칼럼과 salaries 테이블에 존재하는 칼럼 중에서 서로 이름이 같은 칼럼을 모두 조인 조건으로 사용한다. Employees 테이블과 salaries 테이블에는 이름이 같은 칼럼으로 emp_no만 존재하기 때문에 결국 NATURAL JOIN salaries s는 INNER JOIN salaries s ON s.emp_no=e.emp_no와 같은 의미다.
    - NATURAL JOIN은 조인 조건을 명시하지 않아도 된다는 편리함이 있지만 사실 각 테이블의 칼럼 이름에 의해 쿼리가 자동으로 변경될 수 있다는 문제가 있다. 즉 이 조인으로 조인하는 테이블은 같은 칼럼명을 사용할 때 자동으로 조인의 조건으로 사용돼버릴 수 있다는 점을 항상 고려해야 한다. 또한, 애플리케이션이 변경되면서 테이블의 구조를 변경할 때도 NATURAL JOIN으로 조인되는 테이블이 있는지, 그리고 그 테이블의 칼럼과 비교하면서 같은 칼럼명이 존재하는지 확인해야한다. 즉 유지보수를 위한 노력이 많이들기에 사용하지 말자.

- Single-sweep multi join
    - 마스의 네스티드-루프 조인을 자주 single-sweep multi join이라고 표현하기도 한다. 예전의 마스 매뉴얼에서는 조인 방식을 single-sweep multi join이라고 설명했는데 난해하다는 이유로 네스티드-루프 조인이라는 표현으로 바뀌었다. single-sweep multi join의 의미는 조인에 참여하는 테이블의 개수만큼 FOR나 WHILE과 같은 반복 루프가 중첩되는 것을 말한다.

    ```java
    SELECT d.dept_name, e.first_name
    FROM departments d, employees e, dept_emp de
    WHERE de.dept_no=d.dept_no
    	AND e.emp_no=de.emp_no;
    ```

    - 위의 쿼리는 3개의 테이블을 조인하고 있는데, 이 쿼리의 실행 계획은 다음과 같다.

    ![image](https://user-images.githubusercontent.com/37579660/101337958-aef2f880-38bf-11eb-9f3c-8874fcdc3ba0.png)

    - 이 실행 계획을 보면, 제일 먼저 d 테이블이 읽히고 그 다음으로 de 그리고 e 테이블이 읽혔다는 사실을 알 수 있다. 또한 de 와 e 테이블이 읽힐 때 어떤 값이 비교 조건으로 들어왔는지를 ref 칼럼에 표시하고 있다. 이제는 FOR 반복문으로 표시해보자

        ![image](https://user-images.githubusercontent.com/37579660/101337962-b0242580-38bf-11eb-8cf8-75a69e538c80.png)

    - 3번이 중첩되긴 했지만 전체적으로 반복 루프는 1개다. 즉 반복 루프를 돌면서 레코드 단위로 모든 조인 대상 테이블을 차례대로 읽는 방식을 "Single_sweep multi join"이라고 한다. 마스 조인의 결과는 드라이빙 테이블을 읽은 순서대로 레코드가 정렬되어 반환되는 것이다. 조인에서 드리븐 테이블들은 단순히 드라이빙 테이블의 레코드를 읽는 순서대로 검색만 할 뿐이다.

- 조인 버퍼를 이용한 조인 (Using join buffer)
    - 조인은 드라이빙 테이블에서 일치하는 레코드의 건수만큼 드리븐 테이블을 검색하면서 처리된다. 즉, 드라이빙 테이블은 한 번에 쭉 읽게 되지만 드리븐 테이블은 여러 번 읽는다는 것을 의미한다. 예를 들어 드라이빙 테이블에서 일치하는 레코드가 천건이었는데 드리븐 테이블의 조인 조건이 인덱스를 이용할 수 없었다면 드리븐 테이블에서 연결되는 레코드를 찾기 위해 천번의 풀 테이블 스캔을 해야 한다. 그래서 드리븐 테이블을 검색할 때 인덱스를 사용할 수 없는 쿼리는 상당히 느려지며 마스 옵티마이저는 최대한 드리븐 테이블의 검색이 인덱스를 사용할 수 있게 실행 계획을 수립한다.
    - 그런데 어떤 방식으로도 드리븐 테이블의 풀 테이블 스캔이나 인덱스 풀 스캔을 피할 수 없다면 옵티마이저는 드라이빙 테이블에서 읽은 레코드를 메모리에 캐시한 후 드리븐 테이블과 이 메모리 캐시를 조인하는 형태로 처리한다. 이때 사용되는 메모리 캐시를 조인 버퍼라고 한다. 조인 버퍼는 join_buffer_size라는 시스템 설정 변수로 크기를 제한할 수 있으며 조인이 완료되면 조인 버퍼는 바로 해제 된다.
    - 두 테이블이 조인되는 아래의 쿼리에서 각각 테이블에 대한 조건은 WHERE절에 있지만 두 테이블 간의 연결고리 역할을 하는 조인 조건은 없다. 그래서 dept_emp 테이블에서 from_date>1995-01-01인 레코드(124,108건)과 employees 테이블에서 emp_no<109004 조건을 만족하는 레코드(99,003건)는 카테시안 조인을 수행한다.

    ```java
    SELECT *
    FROM dept_emp de, employees e
    WHERE de.from_date>'1995-01-01' AND e.emp_no<109004;
    ```

    - 그리고 아래의 그림은 위의 쿼리가 조인 버퍼 없이 실행될 경우 어떤 절차를 거쳐 결과를 가져오는지 보여준다. Dept_emp 테이블이 드라이빙 테이블이 되고, employees 테이블이 드리븐 테이블이 되어 조인이 수행되는 것으로 가정했다.

    ![image](https://user-images.githubusercontent.com/37579660/101337965-b1555280-38bf-11eb-9dbd-2b5bc8f17f3b.png)

    - dept_emp 테이블에서 조건(from_date>1995-01-01)을 만족하는 각 레코드 별로 employees 테이블에서 emp_no<109004 조건을 만족하는 레코드 99,003건씩 가져온다. 위의 그림을 보면 dept_emp 테이블의 각 레코드에 대해 employees 테이블을 읽을 때 드리븐 테이블에서 가져오는 결과는 매번 같지만 10,161번이나 이 작업을 실행한다는 것을 알 수 있다. 같은 처리를 조인 버퍼를 사용하게 되면 어떻게 달라지는지 한번 살펴보자. 실제 이 쿼리의 실행 계획을 살펴보면 다음과 같이 dept_emp 테이블이 드라이빙 테이블이 되어 조인되고, employees 테이블을 읽을 때는 조인 버퍼를 이용한다는 것을 Extra 칼럼의 내용으로 알 수 있다.

    ![image](https://user-images.githubusercontent.com/37579660/101337967-b2867f80-38bf-11eb-93bf-0b38fb189e44.png)

    - 질문 : 반대로 된 거 같다?
    - 위의 그림에서 중요한 점은 조인 버퍼가 사용되는 쿼리에서는 조인의 순서가 거꾸로인 것처럼 실행된다는 것이다. 위에서 설명한 4번째 단계가 employees 테이블의 결과를 기준으로 dept_emp 테이블의 결과를 결합한다는 것을 의미한다. 실제 이 쿼리의 실행 계획상으로는 dept_emp 테이블이 드라이빙 테이블이 되고, employees 테이블이 드리븐 테이블이 된다. 하지만 실제 드라이빙 테이블의 결과는 조인 버퍼에 담아 두고, 드리븐 테이블을 먼저 읽고 조인 버퍼에서 일치하는 레코드를 찾는 방식으로 처리된다. 일반적으로 조인이 수행된 후 가져오는 결과는 드라이빙 테이블의 순서에 의해 결정되지만 조인 버퍼가 사용되는 조인에서는 결과의 정렬 순서가 흐트러질 수 있음을 기억해야 한다.
    - 조인 버퍼가 사용되는 경우, 처음 읽은 테이블의 결과가 너무 많아서 조인 버퍼에 전부 담지 못하면 위의 1~4까지의 과정을 여러 번 반복한다. 그리고 조인 버퍼에는 조인 쿼리에서 필요로 하는 칼럼만 저장되고, 레코드에 포함된 모든 칼럼은 저장되지 않으므로 상당히 효율적으로 사용된다고 볼 수 있다.

- 조인 관련 주의사항
    - 조인 실행 결과의 정렬 순서
        - 일반적으로 조인으로 쿼리가 실행되는 경우, 드라이빙 테이블로부터 레코드를 읽는 순서가 전체 쿼리의 결과 순서에 그대로 적용되는 것이 일반적이다. 이는 네스티드-루프 조인 방식의 특징이기도 하다.

        ```java
        SELECT de.dept_no, e.emp_no, e.first_name
        FROM dept_emp de, employees e
        WHERE e.emp_no=de.emp_no
        	AND de.dept_no='d005';
        ```

        ![image](https://user-images.githubusercontent.com/37579660/101337972-b3b7ac80-38bf-11eb-82e2-5a7bb85d2ca0.png)

        - 이 쿼리의 실행 계획을 보면 dept_emp 테이블의 프라이머리 키로 먼저 읽었다는 것을 알 수 있다. 그리고 dept_emp 테이블로부터 읽은 결과를 가지고 employees 테이블의 프라이머리 키를 검색하는 과정으로 처리되었다.
        - 이 실행 계획 순서대로 살펴보면 dept_emp 테이블의 프라이머리 키는 (dept_no + emp_no)로 생성돼 있기 때문에 dept_emp 테이블을 검색한 결과는 dept_no 칼럼 순서대로 정렬되고 다시 emp_no로 정렬되어 반환된다는 것을 예상할 수 있다. 그런데 이 쿼리의 WHERE 조건에 dept_no='d005'로 고정돼 있으므로 emp_no로 정렬된 것과 같다. 결국 이 쿼리는 ORDER BY de.emp_no ASC를 명시하지 않았지만 emp_no로 정렬된 효과를 얻을 수 있다. 주로 조인이 인덱스를 이용해 처리되는 경우에는 이러한 예측을 할 수 있다. 하지만 결과가 이 순서로 반환된 것은 옵티마이저가 여러 가지 실행 계획 중에서 위의 실행 계획을 선택했기 때문이다. 만약 옵티마이저가 다른 실행계획을 선택했다면 이런 결과는 보장되지 않는다. 당연히 인덱스를 이용해 검색하고 조인하는 것이 당연스러울 쿼리에서도 테이블의 레코드 건수가 매우 적거나 통계 정보가 잘못돼 있을 때는 다른 실행 계획을 선택할 수도 있다. 이처럼 옵티마이저가 선태가는 실행 계획에 의존한 정렬은 피하는 것이 좋다. 쿼리의 실행 계획은 언제 변경될지 알 수 없기 때문이다. 테이블에 있는 대부분의 레코드가 어느 날 삭제됐다거나 인덱스가 삭제되거나 추가되어 실행 계획이 바뀌는 것은 충분히 가능한 일이기 때문이다.
        - 그러면 위의 쿼리에서 사원 번호로 정렬되어 결과가 반환되기를 바란다면 반드시 ORDER BY de.epm_no ASC 절을 추가해서 정렬이 보장될 수 있게 하자. ORDER BY 절이 쿼리에 명시됐다고 해서 옵티마이저는 항상 정렬 작업을 수행하는 것이 아니다. 실행 계획상에서 이 순서를 보장할 수 있다면 옵티마이저가 자동으로 별도의 정렬 작업을 생략하고 결과를 반환한다. 만약 정렬이 보장되지 않는다면 강제로 정렬 작업을 통해 정렬을 보장해준다. ORDER BY 절이 사용된다고 해서 MySQL 서버가 항상 정렬을 수행하는 것은 아니다. SQL 쿼리에서 결과의 정렬을 보장하는 방법은 ORDER BY 절을 사용하는 것 밖에는 없다는 사실을 잊지 말자.

- INNER JOIN과 OUTER JOIN 선택
    - 이너 조인은 양쪽 테이블 모두 레코드가 존재하는 경우에만 레코드가 반환된다. 하지만 아우터 조인은 아우터 테이블에 존재하면 레코드가 반환된다. 쿼리나 테이블의 구조를 살펴보면 아우터 조인을 사용하지 않아도 될 것을 아우터 조인으로 사용할 때가 상당히 많다. 반대로 아우터 조인으로 실행하면 쿼리가 느려진다고 생각하고 이너조인으로 작성할 때도 있다. 그렇기에 적절한 사용법을 익히는 것이 중요하다.
    - 사실 두 조인 간의 성능 차이는 거의 발생하지 않는다. 실제 비교를 수행하는 건수나, 최종적으로 가져오는 결과 건수가 같다.

        ![image](https://user-images.githubusercontent.com/37579660/101337976-b4e8d980-38bf-11eb-9b1a-d9ece52bd186.png)

    - 전자는 0.37초 후자는0.38초. 후자가 느린 것은 아우터 조인은 조인되는 두번째 테이블 (employees)에서 해당 레코드의 존재 여부를 판단하는 별도의 트리거 조건이 한 번씩 실행되기 때문.
    - 즉 이너와 아우터는 성능을 고려해서 선택할 것이 아니라 업무 조건에 따라 선택하는 것이 바람직하다. 테이블의 구조와 데이터의 특성을 분석해 이너 조인을 사용해야 할지 아우터 조인을 사용해야 할지 결정하자. 데이터의 정확한 구조나 특성을 모르고 아우터 조인을 사용하면 좋지 않다.

## 실행 계획 분석 시 주의사항

실행 계획 분석시 각 칼럼에 표시되는 값 중에서 특별히 주의해서 확인해야 하는 항목만 간략하게 정리했다.

### Select_type

- DERIVED
    - DERIVED는 FROM 절에 사용된 서브 쿼리로부터 발생한 임시 테이블을 의미한다. 임시 테이블은 메모리에 저장될 수도 있고 디스크에 저장될 수도 있다. 일반적으로 메모리에 저장하는 경우에는 크게 성능에 영향을 미치지 않지만, 데이터의 크기가 커서 임시 테이블을 디스크에 저장하면 성능이 떨어진다.

- UNCACHEABLE SUBQUERY
    - 쿼리의 FROM 절 이외의 부분에서 사용하는 서브 쿼리는 가능하면 MySQL 옵티마이저가 최대한 캐시되어 재사용될 수 있게 유도한다. 하지만 사용자 변수나 일부 함수가 사용된 경우에는 이러한 캐시 기능을 사용할 수 없게 만든다. 이런 실행 계획이 사용된다면 혹시 사용자 변수를 제거하거나 다른 함수로 대체해서 사용가능할지 검토해보는 것이 좋다.

- DEPENDENT SUBQUERY
    - 쿼리의 FROM 절 이외의 부분에서 사용하는 서브 쿼리가 자체적으로 실행되지 못하고, 외부 쿼리에서 값을 전달 받아 실행되는 경우에 표시된다. 이는 서브 쿼리가 먼저 실행되지 못하고, 서브 쿼리가 외부 쿼리의 결과 값에 의존적이기 때문에 전체 쿼리의 성능을 느리게 만든다. 서브 쿼리가 불필요하게 외부 쿼리의 값을 전달받고 있는지 검토해서, 가능하다면 외부 쿼리와의 의존도를 제거하는 것이 좋다.

### Type

- ALL, index
    - index는 인덱스 풀 스캔을 의미하며, ALL은 풀 테이블 스캔을 의미한다. 둘 다 대상의 차이만 있지 전체 레코드를 대상으로 하는 작업 방식이라서 빠르게 결과를 가져오기는 어렵다. 일반적인 OLTP환경에 적합한 접근 방식은 아니므로 새로운 인덱스를 추가하거나 쿼리의 요건을 변경해서 이러한 접근 방법을 제거하는 것이 좋다.

### Key

- 쿼리가 인덱스를 사용하지 못할 때 실행 계획의 Key 칼럼에 아무 값도 표시되지 않는다. 쿼리가 인덱스를 사용할 수 있게 인덱스를 추가하거나, WHERE 조건을 변경하는 것이 좋다.

### Rows

- 쿼리가 실제 가져오는 레코드 수보다 훨씬 더 큰 값이 Rows 칼럼에 표시되는 경우에는 쿼리가 인덱스를 정상적으로 사용하고 있는지, 그리고 그 인덱스가 충분히 작업 범위를 좁혀줄 수 있는 칼럼으로 구성됐는지 검토해보는 것이 좋다. 인덱스가 효율적이지 않다면 충분히 식별성을 가지고 있는 칼럼을 선정해 인덱스를 다시 생성하거나 쿼리의 요건을 변경해보는 것이 좋다.
- Rows 칼럼의 수치를 판단할 때 주의해야 할 점은 LIMIT가 포함된 쿼리라 하더라도, LIMIT의 제한은 Rows 칼럼의 고려 대상에서 제외된다는 것이다 .즉 LIMIT 1로 1건만 SELECT 하는 쿼리라 하더라도 Rows 칼럼에는 훨씬 큰 수치가 표현될 수도 있으며, 성능상 아무론 문제도 없고 최적화된 쿼리일 수도 있다는 것이다.

### Extra

- 쿼리를 실행하면서 처리한 주요 작업에 대한 내용이 표시된다. 그렇기에 중요한 단서가 되는 내용이 많다.

- 쿼리가 요건을 제대로 반영하고 있는지 확인해야 하는 경우

![image](https://user-images.githubusercontent.com/37579660/101337981-b61a0680-38bf-11eb-85ea-2deb7f3f2bff.png)

- 위와 같은 코멘트가 Extra 칼럼에 표시된다면 우선 쿼리가 요건을 제대로 반영해서 작성됐거나 버그가 생길 가능성은 없는지 확인해야 한다. 또는 개발용 데이터베이스에 테스트용 레코드가 제대로 준비돼있는지 확인해보는 것도 좋다. 이 항목들은 성능과 관계가 깊지 않고 단지 그런 레코드 없음 이라는 의미가 강하기 때문에 이 쿼리로 인한 버그의 가능성이 있을지를 집중적으로 검토하느 ㄴ것이 좋다. 물론 쿼리가 업무적인 요건을 제대로 반영하고 있다면 무시해도 된다.

- 쿼리의 실행계획이 좋지 않은 경우

    ![image](https://user-images.githubusercontent.com/37579660/101337984-b6b29d00-38bf-11eb-8107-d0a731dd843c.png)

- 위와 같은 코멘트는 쿼리를 최적화할 수 있는지를 검토해보는 것이 좋다. Using where은 사실 대부분의 쿼리에서 표시되는 경향이 있기 때문에 그냥 지나치기 쉬운데, 만약 실행 계획의 Rows 칼럼의 값이 실제 SELECT되는 레코드 건수보다 상당히 높은 경우에는 반드시 보완해서 Rows 칼럼의 값과 실제 SELECT되는 레코드의 수의 차이를 최대한 줄이는 것이 중요하다. 쿼리의 실행 계획에서 이러한 문구가 사라질 수 있다면 최선이겠지만 그렇지 않더라도 성능상 허용 가능하다면 넘어가도 좋다. 단 자세히 검토하자!

- 쿼리의 실행 계획이 좋은 경우

![image](https://user-images.githubusercontent.com/37579660/101337988-b7e3ca00-38bf-11eb-8d61-47238fa4202b.png)

- 최적화되어 처리되고 있음을 알려주는 지표로 생각하자. 특히 Using index는 커버링 인덱스로 처리되고 있음을 알려주는 것인데 마스에서 제공할 수 있는 최고의 성능을 보여줄 것이다. 만약 쿼리를 아무리 최적화해도 성능 요건에 미치지 못한다면 인덱스만으로 쿼리가 처리(커버링 인덱스)되는 형태로 유도해보는 것도 좋다.